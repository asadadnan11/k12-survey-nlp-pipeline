{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# K-12 Survey NLP Pipeline\n",
    "\n",
    "## What I'm trying to do\n",
    "\n",
    "Basically I want to analyze survey responses from K-12 students and teachers to see what they're complaining about and what they like. Going to use some NLP techniques I've been learning about.\n",
    "\n",
    "The plan is to:\n",
    "- Make some fake survey data that looks realistic\n",
    "- Try out VADER sentiment analysis (heard it works well)\n",
    "- Use TF-IDF to find important keywords\n",
    "- Make some charts to visualize everything\n",
    "- Come up with actual recommendations \n",
    "\n",
    "## Why this is interesting:\n",
    "- Want to see if I can identify real patterns in feedback\n",
    "- Practice with NLP libraries I've been reading about\n",
    "- Learn how to turn analysis into business insights\n",
    "- Good portfolio project to show I can work with text data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Need to load all the libraries first. Mostly standard data science + NLP stuff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you need to install stuff\n",
    "# !pip install pandas numpy matplotlib seaborn plotly dash scikit-learn nltk vaderSentiment wordcloud\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# nlp imports - still learning about these\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation  # might try topic modeling\n",
    "from sklearn.cluster import KMeans\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# dashboard stuff - not sure if I'll use this\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # gets rid of annoying warnings\n",
    "\n",
    "# set seeds so results are consistent\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# download nltk data if it's not already there\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except:\n",
    "    print(\"downloading nltk data...\")\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "\n",
    "# make plots look nicer\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"all set!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Generate Fake Survey Data\n",
    "\n",
    "Creating synthetic survey responses that look realistic. Need to cover the usual complaints and praise you'd see in ed-tech:\n",
    "\n",
    "- UI/UX issues (confusing interface, too many clicks)\n",
    "- Performance stuff (slow loading, crashes)  \n",
    "- Engagement problems (boring, too hard/easy)\n",
    "- Technical bugs\n",
    "- Good stuff too (helpful features, works well)\n",
    "\n",
    "Will mix students and teachers across K-12 grades with different sentiment patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_survey_data(num_responses=800):\n",
    "    # create fake survey responses - mix of student and teacher feedback\n",
    "    \n",
    "    student_responses = {\n",
    "        'positive': [\n",
    "            \"I really enjoy using this platform! The interactive lessons make learning fun and engaging.\",\n",
    "            \"The videos are super helpful and easy to understand. I can learn at my own pace.\",\n",
    "            \"Love the colorful design and smooth animations. It makes studying feel like playing games.\",\n",
    "            \"The quizzes are challenging but fair. I feel more confident about the material now.\",\n",
    "            \"Great job on the mobile app! I can study anywhere and sync my progress perfectly.\",\n",
    "            \"The homework help feature is amazing. I get instant feedback and explanations.\",\n",
    "            \"My grades have improved since using this. The personalized learning path works great.\",\n",
    "            \"The community features let me collaborate with classmates easily. Very social and fun!\",\n",
    "            \"Loading is super fast and the interface is intuitive. No technical problems at all.\",\n",
    "            \"The gamification elements motivate me to complete lessons. Badges and points are awesome!\"\n",
    "        ],\n",
    "        'negative': [\n",
    "            \"The interface is way too confusing. I can't find anything and get lost constantly.\",\n",
    "            \"The content moves too fast for me. I wish there were more practice problems.\",\n",
    "            \"The app crashes frequently and I lose my progress. Very frustrating experience.\",\n",
    "            \"The lessons are boring and repetitive. Not engaging at all for students my age.\",\n",
    "            \"Navigation is terrible. Too many clicks to get to simple features.\",\n",
    "            \"The explanations are unclear and hard to follow. Need better examples.\",\n",
    "            \"Loading takes forever and the app freezes often. Makes me not want to use it.\",\n",
    "            \"The design looks outdated and childish. Needs a modern refresh badly.\",\n",
    "            \"Can't access content on mobile properly. Everything is tiny and hard to read.\",\n",
    "            \"The pacing is off - either too easy or impossibly hard. No middle ground.\"\n",
    "        ],\n",
    "        'neutral': [\n",
    "            \"The platform has good content but the user interface could use some improvements.\",\n",
    "            \"Some features work well while others need more development. Mixed experience overall.\",\n",
    "            \"It's okay for basic learning but nothing special compared to other tools.\",\n",
    "            \"The concept is good but execution could be better. Has potential.\",\n",
    "            \"Works fine for homework but could be more engaging for long study sessions.\",\n",
    "            \"Average experience. Gets the job done but doesn't stand out.\",\n",
    "            \"Some lessons are great while others feel rushed. Inconsistent quality.\",\n",
    "            \"The platform serves its purpose but lacks innovative features.\",\n",
    "            \"Decent tool for studying but room for improvement in user experience.\",\n",
    "            \"It's functional but could benefit from more interactive elements.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    teacher_responses = {\n",
    "        'positive': [\n",
    "            \"Excellent tool for classroom management and student engagement tracking.\",\n",
    "            \"The analytics dashboard provides valuable insights into student performance patterns.\",\n",
    "            \"Easy to assign and grade assignments. The automated feedback saves me hours.\",\n",
    "            \"Great integration with our existing curriculum. Seamless workflow integration.\",\n",
    "            \"Students are more engaged with lessons since we started using this platform.\",\n",
    "            \"The professional development resources are comprehensive and well-organized.\",\n",
    "            \"Parent communication features help keep families informed about student progress.\",\n",
    "            \"Customizable lesson plans align perfectly with our district standards.\",\n",
    "            \"The collaboration tools make group projects much easier to manage.\",\n",
    "            \"Robust reporting features help me identify students who need extra support.\"\n",
    "        ],\n",
    "        'negative': [\n",
    "            \"The learning curve is too steep for busy teachers. Need better onboarding.\",\n",
    "            \"Too many features make the interface cluttered and overwhelming to navigate.\",\n",
    "            \"Limited customization options for different teaching styles and preferences.\",\n",
    "            \"Student progress tracking is confusing and hard to interpret meaningfully.\",\n",
    "            \"The platform doesn't integrate well with our school's existing systems.\",\n",
    "            \"Frequent technical issues during class time disrupt lesson flow significantly.\",\n",
    "            \"Lack of adequate training materials for teachers new to the platform.\",\n",
    "            \"The grading system is inflexible and doesn't match our rubrics.\",\n",
    "            \"Parent portal is confusing and generates too many support requests.\",\n",
    "            \"Performance is slow with large class sizes. System can't handle the load.\"\n",
    "        ],\n",
    "        'neutral': [\n",
    "            \"The platform has useful features but requires significant time investment to master.\",\n",
    "            \"Good foundation but needs more development in key areas like assessment tools.\",\n",
    "            \"Meets basic needs but lacks advanced features found in competitor products.\",\n",
    "            \"Adequate for simple tasks but struggles with more complex classroom scenarios.\",\n",
    "            \"Some students adapt well while others find it challenging to use effectively.\",\n",
    "            \"The platform works but doesn't significantly improve upon traditional methods.\",\n",
    "            \"Mixed results - some features are excellent while others need work.\",\n",
    "            \"Functional tool that accomplishes its goals with room for enhancement.\",\n",
    "            \"Reasonable option but not necessarily better than what we used before.\",\n",
    "            \"Standard educational technology platform with typical strengths and weaknesses.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # map grades to groups\n",
    "    grades = list(range(13))  # K=0, then 1-12\n",
    "    grade_map = {}\n",
    "    for g in grades:\n",
    "        if g <= 4:\n",
    "            grade_map[g] = 'Elementary'\n",
    "        elif g <= 8:\n",
    "            grade_map[g] = 'Middle' \n",
    "        else:\n",
    "            grade_map[g] = 'High'\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in range(num_responses):\n",
    "        # pick student or teacher (roughly 60/40 split)\n",
    "        resp_type = 'Student' if random.random() < 0.6 else 'Teacher'\n",
    "        \n",
    "        responses = student_responses if resp_type == 'Student' else teacher_responses\n",
    "        \n",
    "        # sentiment distribution - more positive than negative usually\n",
    "        rand = random.random()\n",
    "        if rand < 0.4:\n",
    "            sentiment = 'positive'\n",
    "        elif rand < 0.75:\n",
    "            sentiment = 'negative'\n",
    "        else:\n",
    "            sentiment = 'neutral'\n",
    "        \n",
    "        text = random.choice(responses[sentiment])\n",
    "        \n",
    "        # grade assignment - students get weighted towards middle, teachers random\n",
    "        if resp_type == 'Student':\n",
    "            # weight toward middle grades\n",
    "            weights = [0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12, 0.11, 0.08, 0.07, 0.06, 0.05]\n",
    "            grade = np.random.choice(grades, p=weights)\n",
    "        else:\n",
    "            grade = random.choice(grades)\n",
    "        \n",
    "        grade_str = 'Kindergarten' if grade == 0 else f'Grade {grade}'\n",
    "        \n",
    "        data.append({\n",
    "            'response_id': f'R{i+1:04d}',\n",
    "            'response_text': text,\n",
    "            'respondent_type': resp_type,\n",
    "            'grade_level': grade_str,\n",
    "            'grade_group': grade_map[grade],\n",
    "            'true_sentiment': sentiment\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# let's create the dataset\n",
    "print(\"generating fake survey data...\")\n",
    "df = generate_survey_data(800)  # trying 800 responses, might adjust later\n",
    "\n",
    "print(f\"created {len(df)} responses\")\n",
    "print(\"\\nrespondent types:\")\n",
    "print(df['respondent_type'].value_counts())\n",
    "print(\"\\ngrade groups:\")\n",
    "print(df['grade_group'].value_counts()) \n",
    "print(\"\\nsentiment breakdown (this is the 'ground truth'):\")\n",
    "print(df['true_sentiment'].value_counts())\n",
    "\n",
    "# let's see what the data looks like\n",
    "print(\"\\nfirst few rows:\")\n",
    "survey_df = df  # keeping this name for consistency later\n",
    "survey_df.head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## NLP Processing\n",
    "\n",
    "Time to actually analyze the text. Going to use:\n",
    "\n",
    "1. Clean up the text (remove stopwords, etc.)\n",
    "2. VADER sentiment analysis (works pretty well for this stuff)\n",
    "3. TF-IDF to find important keywords  \n",
    "4. Maybe some topic modeling if needed\n",
    "\n",
    "This should give us what we need to understand what people are actually complaining about.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurveyNLPProcessor:\n",
    "    # trying to organize all the text processing stuff in one place\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "        self.tfidf_vectorizer = None\n",
    "        self.lda_model = None  # not using this yet but might experiment\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        # this is the standard text cleaning pipeline I learned about\n",
    "        text = text.lower()  # everything lowercase\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # only keep actual words, no punctuation\n",
    "        tokens = [t for t in tokens if t.isalpha()]\n",
    "        \n",
    "        # remove common words that don't add meaning\n",
    "        tokens = [t for t in tokens if t not in self.stop_words]\n",
    "        \n",
    "        # lemmatize - turns words into their base form (running -> run)\n",
    "        tokens = [self.lemmatizer.lemmatize(t) for t in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def analyze_sentiment(self, text):\n",
    "        # use VADER to get sentiment scores\n",
    "        scores = self.sentiment_analyzer.polarity_scores(text)\n",
    "        return {\n",
    "            'positive': scores['pos'],\n",
    "            'negative': scores['neg'], \n",
    "            'neutral': scores['neu'],\n",
    "            'compound': scores['compound']  # this is the main one to use\n",
    "        }\n",
    "    \n",
    "    def extract_keywords_tfidf(self, texts, max_features=100, ngram_range=(1, 2)):\n",
    "        # get keywords using tf-idf\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            ngram_range=ngram_range,\n",
    "            min_df=2,  # need at least 2 docs\n",
    "            max_df=0.8  # ignore super common words\n",
    "        )\n",
    "        \n",
    "        tfidf_matrix = self.tfidf_vectorizer.fit_transform(texts)\n",
    "        feature_names = self.tfidf_vectorizer.get_feature_names_out()\n",
    "        \n",
    "        return feature_names, tfidf_matrix\n",
    "    \n",
    "    def get_top_keywords_by_group(self, df, text_col, group_col, top_n=10):\n",
    "        # get keywords for each group separately\n",
    "        group_keywords = {}\n",
    "        \n",
    "        for group in df[group_col].unique():\n",
    "            group_texts = df[df[group_col] == group][text_col].tolist()\n",
    "            \n",
    "            vectorizer = TfidfVectorizer(\n",
    "                max_features=200,\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=1,\n",
    "                stop_words='english'\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                tfidf_matrix = vectorizer.fit_transform(group_texts)\n",
    "                feature_names = vectorizer.get_feature_names_out()\n",
    "                \n",
    "                # Calculate mean TF-IDF scores\n",
    "                mean_scores = np.mean(tfidf_matrix.toarray(), axis=0)\n",
    "                \n",
    "                # Get top keywords\n",
    "                top_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
    "                top_keywords = [(feature_names[i], mean_scores[i]) for i in top_indices]\n",
    "                \n",
    "                group_keywords[group] = top_keywords\n",
    "                \n",
    "            except ValueError:\n",
    "                # Handle case where group has insufficient data\n",
    "                group_keywords[group] = []\n",
    "                \n",
    "        return group_keywords\n",
    "\n",
    "# let's set up the NLP processor and run it\n",
    "print(\"setting up NLP processor...\")\n",
    "nlp_processor = SurveyNLPProcessor()\n",
    "\n",
    "# clean up all the text data\n",
    "print(\"preprocessing all the text...\")\n",
    "survey_df['processed_text'] = survey_df['response_text'].apply(nlp_processor.preprocess_text)\n",
    "\n",
    "# run VADER sentiment analysis on each response\n",
    "print(\"running VADER sentiment analysis...\")\n",
    "sentiment_results = survey_df['response_text'].apply(nlp_processor.analyze_sentiment)\n",
    "sentiment_df = pd.DataFrame(sentiment_results.tolist())\n",
    "survey_df = pd.concat([survey_df, sentiment_df], axis=1)\n",
    "\n",
    "# convert compound scores to actual labels\n",
    "# I read that VADER uses +/- 0.05 as the typical thresholds\n",
    "def classify_sentiment(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "survey_df['predicted_sentiment'] = survey_df['compound'].apply(classify_sentiment)\n",
    "\n",
    "# extract keywords for different groups\n",
    "print(\"extracting keywords using TF-IDF...\")\n",
    "student_teacher_keywords = nlp_processor.get_top_keywords_by_group(\n",
    "    survey_df, 'processed_text', 'respondent_type', top_n=15\n",
    ")\n",
    "\n",
    "grade_group_keywords = nlp_processor.get_top_keywords_by_group(\n",
    "    survey_df, 'processed_text', 'grade_group', top_n=15\n",
    ")\n",
    "\n",
    "# let's see how well it worked\n",
    "print(\"done with NLP processing!\")\n",
    "print(f\"\\nSentiment analysis results:\")\n",
    "accuracy = (survey_df['true_sentiment'].str.title() == survey_df['predicted_sentiment']).mean()\n",
    "print(f\"accuracy: {accuracy:.2%} (not bad for unsupervised!)\")\n",
    "\n",
    "print(f\"\\nPredicted sentiment breakdown:\")\n",
    "print(survey_df['predicted_sentiment'].value_counts())\n",
    "\n",
    "# take a look at some examples\n",
    "print(f\"\\nSample of processed data:\")\n",
    "display_cols = ['response_text', 'respondent_type', 'grade_group', 'predicted_sentiment', 'compound']\n",
    "survey_df[display_cols].head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Data Visualization and Analysis\n",
    "\n",
    "Let's create comprehensive visualizations to understand the patterns in our survey data. We'll explore:\n",
    "\n",
    "1. **Keyword Analysis**: Top terms by respondent type and grade group\n",
    "2. **Sentiment Distribution**: How sentiment varies across different segments\n",
    "3. **Grade Level Insights**: Patterns across elementary, middle, and high school\n",
    "4. **Word Clouds**: Visual representation of key themes\n",
    "5. **Correlation Analysis**: Relationships between different variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Keyword Analysis Visualization\n",
    "\n",
    "def plot_top_keywords(keywords_dict, title, top_n=10):\n",
    "    \"\"\"Create horizontal bar plot for top keywords\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(keywords_dict), figsize=(16, 8))\n",
    "    if len(keywords_dict) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (group, keywords) in enumerate(keywords_dict.items()):\n",
    "        if keywords:  # Check if keywords exist for this group\n",
    "            words, scores = zip(*keywords[:top_n])\n",
    "            axes[i].barh(range(len(words)), scores, color=sns.color_palette(\"husl\", len(keywords_dict))[i])\n",
    "            axes[i].set_yticks(range(len(words)))\n",
    "            axes[i].set_yticklabels(words)\n",
    "            axes[i].set_xlabel('TF-IDF Score')\n",
    "            axes[i].set_title(f'{group}')\n",
    "            axes[i].invert_yaxis()\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot keywords by respondent type\n",
    "print(\"Top Keywords by Respondent Type\")\n",
    "plot_top_keywords(student_teacher_keywords, \"Top Keywords: Students vs Teachers\", top_n=12)\n",
    "\n",
    "# Plot keywords by grade group\n",
    "print(\"\\nTop Keywords by Grade Group\")\n",
    "plot_top_keywords(grade_group_keywords, \"Top Keywords by Grade Group\", top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Sentiment Analysis Visualizations\n",
    "\n",
    "# Create sentiment distribution plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Overall sentiment distribution\n",
    "sentiment_counts = survey_df['predicted_sentiment'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c', '#95a5a6']  # Green, Red, Gray\n",
    "axes[0,0].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%', \n",
    "              colors=colors, startangle=90)\n",
    "axes[0,0].set_title('Overall Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Sentiment by respondent type\n",
    "sentiment_by_type = pd.crosstab(survey_df['respondent_type'], survey_df['predicted_sentiment'])\n",
    "sentiment_by_type.plot(kind='bar', ax=axes[0,1], color=colors, rot=0)\n",
    "axes[0,1].set_title('Sentiment by Respondent Type', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Respondent Type')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "axes[0,1].legend(title='Sentiment')\n",
    "\n",
    "# 3. Sentiment by grade group\n",
    "sentiment_by_grade = pd.crosstab(survey_df['grade_group'], survey_df['predicted_sentiment'])\n",
    "sentiment_by_grade.plot(kind='bar', ax=axes[1,0], color=colors, rot=0)\n",
    "axes[1,0].set_title('Sentiment by Grade Group', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Grade Group')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].legend(title='Sentiment')\n",
    "\n",
    "# 4. Sentiment score distribution\n",
    "axes[1,1].hist(survey_df['compound'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[1,1].axvline(x=0.05, color='green', linestyle='--', label='Positive Threshold')\n",
    "axes[1,1].axvline(x=-0.05, color='red', linestyle='--', label='Negative Threshold')\n",
    "axes[1,1].set_title('Distribution of Compound Sentiment Scores', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Compound Score')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate sentiment statistics\n",
    "print(\"Sentiment Analysis Summary:\")\n",
    "print(f\"Average Sentiment Score: {survey_df['compound'].mean():.3f}\")\n",
    "print(f\"Sentiment Standard Deviation: {survey_df['compound'].std():.3f}\")\n",
    "\n",
    "# Sentiment by respondent type analysis\n",
    "print(f\"\\nAverage Sentiment by Respondent Type:\")\n",
    "sentiment_by_type_avg = survey_df.groupby('respondent_type')['compound'].agg(['mean', 'std', 'count'])\n",
    "print(sentiment_by_type_avg.round(3))\n",
    "\n",
    "print(f\"\\nAverage Sentiment by Grade Group:\")\n",
    "sentiment_by_grade_avg = survey_df.groupby('grade_group')['compound'].agg(['mean', 'std', 'count'])\n",
    "print(sentiment_by_grade_avg.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Word Clouds and Advanced Visualizations\n",
    "\n",
    "def create_wordcloud(text_data, title, colormap='viridis'):\n",
    "    \"\"\"Create and display word cloud\"\"\"\n",
    "    text = ' '.join(text_data)\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400, \n",
    "        background_color='white',\n",
    "        colormap=colormap,\n",
    "        max_words=100,\n",
    "        relative_scaling=0.5,\n",
    "        random_state=42\n",
    "    ).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create word clouds for different groups\n",
    "print(\"Word Cloud Visualizations\")\n",
    "\n",
    "# Word cloud for all responses\n",
    "create_wordcloud(survey_df['processed_text'], \"Word Cloud: All Survey Responses\", 'plasma')\n",
    "\n",
    "# Word clouds by respondent type\n",
    "student_text = survey_df[survey_df['respondent_type'] == 'Student']['processed_text']\n",
    "teacher_text = survey_df[survey_df['respondent_type'] == 'Teacher']['processed_text']\n",
    "\n",
    "create_wordcloud(student_text, \"Word Cloud: Student Responses\", 'Blues')\n",
    "create_wordcloud(teacher_text, \"Word Cloud: Teacher Responses\", 'Reds')\n",
    "\n",
    "# Word clouds by sentiment\n",
    "positive_text = survey_df[survey_df['predicted_sentiment'] == 'Positive']['processed_text']\n",
    "negative_text = survey_df[survey_df['predicted_sentiment'] == 'Negative']['processed_text']\n",
    "\n",
    "create_wordcloud(positive_text, \"Word Cloud: Positive Feedback\", 'Greens')\n",
    "create_wordcloud(negative_text, \"Word Cloud: Negative Feedback\", 'Reds')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Interactive Dashboard (Tableau-like Visualization)\n",
    "\n",
    "We'll create an interactive dashboard using Plotly that allows stakeholders to explore the data dynamically. This dashboard includes:\n",
    "\n",
    "1. **Interactive Sentiment Explorer**: Filter by grade level and respondent type\n",
    "2. **Keyword Frequency Analysis**: Dynamic keyword exploration\n",
    "3. **Trend Analysis**: Patterns across different segments\n",
    "4. **Pain Point Identification**: Focus on negative feedback themes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Interactive Plotly Dashboard Components\n",
    "\n",
    "# Create interactive sentiment analysis dashboard\n",
    "def create_interactive_dashboard():\n",
    "    \"\"\"Create comprehensive interactive dashboard\"\"\"\n",
    "    \n",
    "    # 1. Interactive Sentiment Distribution by Grade Level\n",
    "    fig1 = px.sunburst(\n",
    "        survey_df, \n",
    "        path=['grade_group', 'respondent_type', 'predicted_sentiment'],\n",
    "        title=\"Interactive Sentiment Distribution: Grade Group → Respondent Type → Sentiment\",\n",
    "        color='compound',\n",
    "        color_continuous_scale='RdYlGn',\n",
    "        height=600\n",
    "    )\n",
    "    fig1.update_layout(title_font_size=16)\n",
    "    fig1.show()\n",
    "    \n",
    "    # 2. Interactive Scatter Plot: Sentiment Scores\n",
    "    fig2 = px.scatter(\n",
    "        survey_df, \n",
    "        x='positive', \n",
    "        y='negative',\n",
    "        size='neutral',\n",
    "        color='predicted_sentiment',\n",
    "        hover_data=['respondent_type', 'grade_group'],\n",
    "        title=\"Sentiment Score Analysis: Positive vs Negative (Size = Neutral)\",\n",
    "        color_discrete_map={'Positive': '#2ecc71', 'Negative': '#e74c3c', 'Neutral': '#95a5a6'}\n",
    "    )\n",
    "    fig2.update_layout(title_font_size=16, height=500)\n",
    "    fig2.show()\n",
    "    \n",
    "    # 3. Interactive Heatmap: Sentiment by Grade and Type\n",
    "    pivot_data = survey_df.pivot_table(\n",
    "        values='compound', \n",
    "        index='grade_level', \n",
    "        columns='respondent_type', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    fig3 = px.imshow(\n",
    "        pivot_data,\n",
    "        title=\"Sentiment Heatmap: Average Compound Score by Grade Level and Respondent Type\",\n",
    "        color_continuous_scale='RdYlGn',\n",
    "        aspect=\"auto\",\n",
    "        height=600\n",
    "    )\n",
    "    fig3.update_layout(title_font_size=16)\n",
    "    fig3.show()\n",
    "    \n",
    "    # 4. Interactive Box Plot: Sentiment Distribution\n",
    "    fig4 = px.box(\n",
    "        survey_df, \n",
    "        x='grade_group', \n",
    "        y='compound',\n",
    "        color='respondent_type',\n",
    "        title=\"Sentiment Score Distribution by Grade Group and Respondent Type\",\n",
    "        points=\"outliers\"\n",
    "    )\n",
    "    fig4.update_layout(title_font_size=16, height=500)\n",
    "    fig4.show()\n",
    "    \n",
    "    return fig1, fig2, fig3, fig4\n",
    "\n",
    "print(\"Creating Interactive Dashboard...\")\n",
    "dashboard_figs = create_interactive_dashboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword analysis - let's see what themes come up\n",
    "\n",
    "def keyword_analysis():\n",
    "    # prep data for viz\n",
    "    keyword_data = []\n",
    "    \n",
    "    # get keywords by respondent type\n",
    "    for resp_type in ['Student', 'Teacher']:\n",
    "        if resp_type in student_teacher_keywords:\n",
    "            for keyword, score in student_teacher_keywords[resp_type][:10]:\n",
    "                keyword_data.append({\n",
    "                    'keyword': keyword,\n",
    "                    'score': score,\n",
    "                    'respondent_type': resp_type,\n",
    "                    'category': 'Respondent Type'\n",
    "                })\n",
    "    \n",
    "    # Extract keywords for each grade group\n",
    "    for grade_group in ['Elementary', 'Middle', 'High']:\n",
    "        if grade_group in grade_group_keywords:\n",
    "            for keyword, score in grade_group_keywords[grade_group][:8]:\n",
    "                keyword_data.append({\n",
    "                    'keyword': keyword,\n",
    "                    'score': score,\n",
    "                    'grade_group': grade_group,\n",
    "                    'category': 'Grade Group'\n",
    "                })\n",
    "    \n",
    "    keyword_df = pd.DataFrame(keyword_data)\n",
    "    \n",
    "    # 1. Interactive Keyword Comparison\n",
    "    if not keyword_df.empty and 'respondent_type' in keyword_df.columns:\n",
    "        resp_type_keywords = keyword_df[keyword_df['category'] == 'Respondent Type']\n",
    "        if not resp_type_keywords.empty:\n",
    "            fig1 = px.bar(\n",
    "                resp_type_keywords,\n",
    "                x='score',\n",
    "                y='keyword',\n",
    "                color='respondent_type',\n",
    "                orientation='h',\n",
    "                title=\"Top Keywords Comparison: Students vs Teachers\",\n",
    "                labels={'score': 'TF-IDF Score', 'keyword': 'Keywords'},\n",
    "                height=600\n",
    "            )\n",
    "            fig1.update_layout(\n",
    "                title_font_size=16,\n",
    "                yaxis={'categoryorder': 'total ascending'}\n",
    "            )\n",
    "            fig1.show()\n",
    "    \n",
    "    # 2. Grade Group Keyword Analysis\n",
    "    if 'grade_group' in keyword_df.columns:\n",
    "        grade_keywords = keyword_df[keyword_df['category'] == 'Grade Group']\n",
    "        if not grade_keywords.empty:\n",
    "            fig2 = px.scatter(\n",
    "                grade_keywords,\n",
    "                x='grade_group',\n",
    "                y='score',\n",
    "                size='score',\n",
    "                hover_name='keyword',\n",
    "                title=\"Keyword Importance Across Grade Groups\",\n",
    "                labels={'score': 'TF-IDF Score', 'grade_group': 'Grade Group'},\n",
    "                height=500\n",
    "            )\n",
    "            fig2.update_layout(title_font_size=16)\n",
    "            fig2.show()\n",
    "    \n",
    "    # 3. Sentiment-based keyword analysis\n",
    "    sentiment_keywords = {}\n",
    "    for sentiment in ['Positive', 'Negative', 'Neutral']:\n",
    "        sentiment_text = survey_df[survey_df['predicted_sentiment'] == sentiment]['processed_text']\n",
    "        if len(sentiment_text) > 0:\n",
    "            sentiment_keywords[sentiment] = nlp_processor.get_top_keywords_by_group(\n",
    "                survey_df[survey_df['predicted_sentiment'] == sentiment], \n",
    "                'processed_text', \n",
    "                'predicted_sentiment', \n",
    "                top_n=10\n",
    "            )\n",
    "    \n",
    "    # Create sentiment keyword visualization\n",
    "    sentiment_keyword_data = []\n",
    "    for sentiment, keywords_dict in sentiment_keywords.items():\n",
    "        if sentiment in keywords_dict:\n",
    "            for keyword, score in keywords_dict[sentiment][:8]:\n",
    "                sentiment_keyword_data.append({\n",
    "                    'keyword': keyword,\n",
    "                    'score': score,\n",
    "                    'sentiment': sentiment\n",
    "                })\n",
    "    \n",
    "    if sentiment_keyword_data:\n",
    "        sentiment_keyword_df = pd.DataFrame(sentiment_keyword_data)\n",
    "        fig3 = px.treemap(\n",
    "            sentiment_keyword_df,\n",
    "            path=['sentiment', 'keyword'],\n",
    "            values='score',\n",
    "            title=\"Keyword Themes by Sentiment (Treemap)\",\n",
    "            color='score',\n",
    "            color_continuous_scale='RdYlGn',\n",
    "            height=600\n",
    "        )\n",
    "        fig3.update_layout(title_font_size=16)\n",
    "        fig3.show()\n",
    "    \n",
    "    return keyword_df\n",
    "\n",
    "print(\"running keyword analysis...\")\n",
    "keyword_analysis_df = keyword_analysis()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## What this means for the product\n",
    "\n",
    "Now that we've analyzed everything, time to figure out what we should actually do about it. What are the main problems and how can we fix them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's figure out what's making people mad\n",
    "\n",
    "def analyze_pain_points():\n",
    "    # filter to just the negative stuff\n",
    "    negative_feedback = survey_df[survey_df['predicted_sentiment'] == 'Negative']\n",
    "    \n",
    "    print(\"PAIN POINTS - what's going wrong\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"Negative responses: {len(negative_feedback)} total\")\n",
    "    # break it down by respondent type\n",
    "    student_neg = len(negative_feedback[negative_feedback['respondent_type'] == 'Student'])\n",
    "    teacher_neg = len(negative_feedback[negative_feedback['respondent_type'] == 'Teacher'])\n",
    "    print(f\"Students: {student_neg}\")\n",
    "    print(f\"Teachers: {teacher_neg}\")\n",
    "    \n",
    "    # which grade groups are most unhappy?\n",
    "    print(f\"\\nBy grade group:\")\n",
    "    negative_by_grade = negative_feedback['grade_group'].value_counts()\n",
    "    for grade, count in negative_by_grade.items():\n",
    "        pct = (count / len(negative_feedback)) * 100\n",
    "        print(f\"• {grade}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # try to extract keywords from the negative feedback\n",
    "    # this should tell us what specific things people are complaining about\n",
    "    if len(negative_feedback) > 0:\n",
    "        pain_point_keywords = nlp_processor.get_top_keywords_by_group(\n",
    "            negative_feedback, 'processed_text', 'respondent_type', top_n=15\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTop Pain Point Keywords:\")\n",
    "        for resp_type, keywords in pain_point_keywords.items():\n",
    "            print(f\"\\n{resp_type} Pain Points:\")\n",
    "            for i, (keyword, score) in enumerate(keywords[:10], 1):\n",
    "                print(f\"  {i}. {keyword} (TF-IDF: {score:.3f})\")\n",
    "    \n",
    "    # 4. Sentiment severity analysis\n",
    "    print(f\"\\nSentiment Severity Analysis:\")\n",
    "    very_negative = negative_feedback[negative_feedback['compound'] <= -0.5]\n",
    "    moderately_negative = negative_feedback[\n",
    "        (negative_feedback['compound'] > -0.5) & (negative_feedback['compound'] <= -0.05)\n",
    "    ]\n",
    "    \n",
    "    print(f\"• Very Negative (≤ -0.5): {len(very_negative)} responses\")\n",
    "    print(f\"• Moderately Negative (-0.5 to -0.05): {len(moderately_negative)} responses\")\n",
    "    \n",
    "    return negative_feedback, pain_point_keywords\n",
    "\n",
    "def product_recommendations():\n",
    "    # okay so what should we actually fix based on this analysis?\n",
    "    \n",
    "    print(\"\\n\\nWHAT TO FIX\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # let me calculate some basic stats first\n",
    "    total = len(survey_df)\n",
    "    negative_rate = len(survey_df[survey_df['predicted_sentiment'] == 'Negative']) / total\n",
    "    student_sentiment = survey_df[survey_df['respondent_type'] == 'Student']['compound'].mean()\n",
    "    teacher_sentiment = survey_df[survey_df['respondent_type'] == 'Teacher']['compound'].mean()\n",
    "    \n",
    "    print(f\"Key numbers:\")\n",
    "    print(f\"- Negative feedback rate: {negative_rate:.1%}\")\n",
    "    print(f\"- Student avg sentiment: {student_sentiment:.3f}\")\n",
    "    print(f\"- Teacher avg sentiment: {teacher_sentiment:.3f}\")\n",
    "    print(f\"- Gap: {teacher_sentiment - student_sentiment:.3f}\")\n",
    "    \n",
    "    print(f\"\\nTOP PRIORITIES:\")\n",
    "    # trying to prioritize based on frequency of complaints\n",
    "    \n",
    "    # UI/UX problems\n",
    "    ui_keywords = ['interface', 'navigation', 'design', 'confusing', 'click']\n",
    "    ui_mentions = survey_df[survey_df['processed_text'].str.contains('|'.join(ui_keywords), na=False)]\n",
    "    \n",
    "    print(f\"\\n1. FIX THE UI (HIGH PRIORITY)\")\n",
    "    print(f\"   - {len(ui_mentions)} people complaining about UI/navigation\")\n",
    "    print(f\"   - Make navigation simpler, less clicks\")\n",
    "    print(f\"   - Test with actual users from different grades\")\n",
    "    print(f\"   - Reduce cognitive load - too much going on\")\n",
    "    \n",
    "    # Performance stuff\n",
    "    perf_keywords = ['slow', 'loading', 'crash', 'freeze', 'performance']\n",
    "    perf_mentions = survey_df[survey_df['processed_text'].str.contains('|'.join(perf_keywords), na=False)]\n",
    "    \n",
    "    print(f\"\\n2. PERFORMANCE ISSUES (HIGH PRIORITY)\")\n",
    "    print(f\"   - {len(perf_mentions)} responses about slowness/crashes\")\n",
    "    print(f\"   - Add performance monitoring\")\n",
    "    print(f\"   - Optimize for mobile and slow connections\")\n",
    "    print(f\"   - Loading indicators so people know something's happening\")\n",
    "    \n",
    "    # Recommendation 3: Engagement Features\n",
    "    engagement_keywords = ['boring', 'engaging', 'fun', 'interactive', 'motivation']\n",
    "    engagement_mentions = survey_df[survey_df['processed_text'].str.contains('|'.join(engagement_keywords), na=False)]\n",
    "    \n",
    "    print(f\"\\n3. ENGAGEMENT ENHANCEMENT (Priority: MEDIUM)\")\n",
    "    print(f\"   - {len(engagement_mentions)} responses mention engagement aspects\")\n",
    "    print(f\"   - Expand gamification elements based on positive feedback\")\n",
    "    print(f\"   - Add more interactive content and collaborative features\")\n",
    "    print(f\"   - Personalize learning experiences by grade level\")\n",
    "    \n",
    "    # Recommendation 4: Teacher-Specific Improvements\n",
    "    if teacher_avg_sentiment < student_avg_sentiment:\n",
    "        print(f\"\\n4. TEACHER EXPERIENCE FOCUS (Priority: MEDIUM)\")\n",
    "        print(f\"   - Teachers show {abs(teacher_avg_sentiment - student_avg_sentiment):.3f} lower sentiment\")\n",
    "        print(f\"   - Simplify administrative and grading workflows\")\n",
    "        print(f\"   - Improve integration with existing school systems\")\n",
    "        print(f\"   - Provide better onboarding and training resources\")\n",
    "    \n",
    "    # Recommendation 5: Grade-Specific Optimizations\n",
    "    grade_sentiment = survey_df.groupby('grade_group')['compound'].mean()\n",
    "    lowest_sentiment_grade = grade_sentiment.idxmin()\n",
    "    \n",
    "    print(f\"\\n5. GRADE-SPECIFIC OPTIMIZATION (Priority: MEDIUM)\")\n",
    "    print(f\"   - {lowest_sentiment_grade} grade group shows lowest sentiment ({grade_sentiment[lowest_sentiment_grade]:.3f})\")\n",
    "    print(f\"   - Customize interface complexity for different age groups\")\n",
    "    print(f\"   - Adapt content pacing and difficulty curves\")\n",
    "    print(f\"   - Implement age-appropriate design patterns\")\n",
    "    \n",
    "    return {\n",
    "        'negative_rate': negative_rate,\n",
    "        'student_sentiment': student_avg_sentiment,\n",
    "        'teacher_sentiment': teacher_avg_sentiment,\n",
    "        'lowest_grade_group': lowest_sentiment_grade,\n",
    "        'ui_issues': len(ui_mentions),\n",
    "        'performance_issues': len(perf_mentions),\n",
    "        'engagement_issues': len(engagement_mentions)\n",
    "    }\n",
    "\n",
    "def create_executive_summary():\n",
    "    \"\"\"Create executive summary with key findings\"\"\"\n",
    "    \n",
    "    print(f\"\\n\\nEXECUTIVE SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_responses = len(survey_df)\n",
    "    sentiment_dist = survey_df['predicted_sentiment'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(f\"SURVEY OVERVIEW:\")\n",
    "    print(f\"- Total Responses Analyzed: {total_responses}\")\n",
    "    print(f\"- Students: {len(survey_df[survey_df['respondent_type'] == 'Student'])} ({len(survey_df[survey_df['respondent_type'] == 'Student'])/total_responses:.1%})\")\n",
    "    print(f\"- Teachers: {len(survey_df[survey_df['respondent_type'] == 'Teacher'])} ({len(survey_df[survey_df['respondent_type'] == 'Teacher'])/total_responses:.1%})\")\n",
    "    \n",
    "    print(f\"\\nKEY FINDINGS:\")\n",
    "    print(f\"- Positive Sentiment: {sentiment_dist.get('Positive', 0):.1f}%\")\n",
    "    print(f\"- Negative Sentiment: {sentiment_dist.get('Negative', 0):.1f}%\")\n",
    "    print(f\"- Neutral Sentiment: {sentiment_dist.get('Neutral', 0):.1f}%\")\n",
    "    \n",
    "    # Top positive and negative themes\n",
    "    positive_responses = survey_df[survey_df['predicted_sentiment'] == 'Positive']['processed_text']\n",
    "    negative_responses = survey_df[survey_df['predicted_sentiment'] == 'Negative']['processed_text']\n",
    "    \n",
    "    print(f\"\\nTOP POSITIVE THEMES:\")\n",
    "    print(f\"- Interactive and engaging content\")\n",
    "    print(f\"- Helpful video explanations and examples\")\n",
    "    print(f\"- Gamification and motivational features\")\n",
    "    print(f\"- Mobile accessibility and progress syncing\")\n",
    "    \n",
    "    print(f\"\\nTOP NEGATIVE THEMES:\")\n",
    "    print(f\"- Complex and confusing user interface\")\n",
    "    print(f\"- Performance and loading issues\")\n",
    "    print(f\"- Content pacing problems (too fast/slow)\")\n",
    "    print(f\"- Limited customization and flexibility\")\n",
    "    \n",
    "    print(f\"\\nIMMEDIATE ACTION ITEMS:\")\n",
    "    print(f\"- Prioritize UI/UX simplification project\")\n",
    "    print(f\"- Implement performance monitoring and optimization\")\n",
    "    print(f\"- Develop grade-specific interface adaptations\")\n",
    "    print(f\"- Enhance teacher onboarding and training programs\")\n",
    "\n",
    "# run the analysis\n",
    "negative_feedback, pain_points = analyze_pain_points()\n",
    "recommendations = product_recommendations()\n",
    "create_executive_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Interactive Dash Application\n",
    "\n",
    "Below is a sample Dash application that could be deployed to provide real-time exploration of the survey data. This would allow stakeholders to filter and explore the data interactively in a web browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Sample Dash Application for Real-time Dashboard\n",
    "\n",
    "def create_dash_app():\n",
    "    \"\"\"\n",
    "    Create a Dash application for interactive survey data exploration\n",
    "    Note: This is a demonstration - to run, uncomment the app.run_server() line\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize Dash app\n",
    "    app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "    \n",
    "    # Define app layout\n",
    "    app.layout = dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.H1(\"K-12 Survey NLP Insights Dashboard\", className=\"text-center mb-4\"),\n",
    "                html.Hr()\n",
    "            ])\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.Label(\"Select Respondent Type:\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='respondent-filter',\n",
    "                    options=[\n",
    "                        {'label': 'All', 'value': 'All'},\n",
    "                        {'label': 'Student', 'value': 'Student'},\n",
    "                        {'label': 'Teacher', 'value': 'Teacher'}\n",
    "                    ],\n",
    "                    value='All'\n",
    "                )\n",
    "            ], width=4),\n",
    "            \n",
    "            dbc.Col([\n",
    "                html.Label(\"Select Grade Group:\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='grade-filter',\n",
    "                    options=[\n",
    "                        {'label': 'All', 'value': 'All'},\n",
    "                        {'label': 'Elementary', 'value': 'Elementary'},\n",
    "                        {'label': 'Middle', 'value': 'Middle'},\n",
    "                        {'label': 'High', 'value': 'High'}\n",
    "                    ],\n",
    "                    value='All'\n",
    "                )\n",
    "            ], width=4),\n",
    "            \n",
    "            dbc.Col([\n",
    "                html.Label(\"Select Sentiment:\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='sentiment-filter',\n",
    "                    options=[\n",
    "                        {'label': 'All', 'value': 'All'},\n",
    "                        {'label': 'Positive', 'value': 'Positive'},\n",
    "                        {'label': 'Negative', 'value': 'Negative'},\n",
    "                        {'label': 'Neutral', 'value': 'Neutral'}\n",
    "                    ],\n",
    "                    value='All'\n",
    "                )\n",
    "            ], width=4)\n",
    "        ], className=\"mb-4\"),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dcc.Graph(id='sentiment-distribution')\n",
    "            ], width=6),\n",
    "            dbc.Col([\n",
    "                dcc.Graph(id='keyword-analysis')\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dcc.Graph(id='sentiment-heatmap')\n",
    "            ], width=12)\n",
    "        ], className=\"mt-4\")\n",
    "    ], fluid=True)\n",
    "    \n",
    "    # Callback for updating charts based on filters\n",
    "    @app.callback(\n",
    "        [Output('sentiment-distribution', 'figure'),\n",
    "         Output('keyword-analysis', 'figure'),\n",
    "         Output('sentiment-heatmap', 'figure')],\n",
    "        [Input('respondent-filter', 'value'),\n",
    "         Input('grade-filter', 'value'),\n",
    "         Input('sentiment-filter', 'value')]\n",
    "    )\n",
    "    def update_dashboard(respondent_type, grade_group, sentiment):\n",
    "        # Filter data based on selections\n",
    "        filtered_df = survey_df.copy()\n",
    "        \n",
    "        if respondent_type != 'All':\n",
    "            filtered_df = filtered_df[filtered_df['respondent_type'] == respondent_type]\n",
    "        if grade_group != 'All':\n",
    "            filtered_df = filtered_df[filtered_df['grade_group'] == grade_group]\n",
    "        if sentiment != 'All':\n",
    "            filtered_df = filtered_df[filtered_df['predicted_sentiment'] == sentiment]\n",
    "        \n",
    "        # Create sentiment distribution chart\n",
    "        sentiment_counts = filtered_df['predicted_sentiment'].value_counts()\n",
    "        fig1 = px.pie(\n",
    "            values=sentiment_counts.values,\n",
    "            names=sentiment_counts.index,\n",
    "            title=\"Sentiment Distribution\"\n",
    "        )\n",
    "        \n",
    "        # Create keyword frequency chart (simplified)\n",
    "        word_freq = {}\n",
    "        for text in filtered_df['processed_text']:\n",
    "            words = text.split()\n",
    "            for word in words[:5]:  # Top 5 words per response\n",
    "                word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        \n",
    "        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        if top_words:\n",
    "            words, freqs = zip(*top_words)\n",
    "            fig2 = px.bar(x=list(freqs), y=list(words), orientation='h', \n",
    "                         title=\"Top Keywords\")\n",
    "        else:\n",
    "            fig2 = px.bar(title=\"No data available\")\n",
    "        \n",
    "        # Create sentiment heatmap\n",
    "        if len(filtered_df) > 0:\n",
    "            heatmap_data = filtered_df.pivot_table(\n",
    "                values='compound', \n",
    "                index='grade_group', \n",
    "                columns='respondent_type', \n",
    "                aggfunc='mean'\n",
    "            )\n",
    "            fig3 = px.imshow(heatmap_data, title=\"Average Sentiment by Group\")\n",
    "        else:\n",
    "            fig3 = px.imshow([[0]], title=\"No data available\")\n",
    "        \n",
    "        return fig1, fig2, fig3\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create the app (but don't run it in notebook)\n",
    "print(\"Creating Dash application...\")\n",
    "dash_app = create_dash_app()\n",
    "\n",
    "print(\"Dash application created successfully!\")\n",
    "print(\"To run the dashboard, uncomment the following line:\")\n",
    "print(\"# dash_app.run_server(debug=True, port=8050)\")\n",
    "\n",
    "print(\"\\nNote: The dashboard would be available at http://localhost:8050 when running.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Wrapping up\n",
    "\n",
    "So what did we accomplish here?\n",
    "\n",
    "### What worked:\n",
    "- Made 800 fake survey responses that look realistic\n",
    "- Used VADER sentiment analysis and TF-IDF for keyword extraction\n",
    "- Built some decent visualizations to see patterns\n",
    "- Found the main pain points (UI problems, performance issues)\n",
    "- Made recommendations that actually make sense\n",
    "\n",
    "### Technical stuff:\n",
    "- Code is modular enough to reuse\n",
    "- Used standard libraries (sklearn, nltk, plotly)\n",
    "- Dashboard prototype with Dash (though not running here)\n",
    "- Could handle real data if we plugged it in\n",
    "\n",
    "### Business impact:\n",
    "- We can actually see what grade levels hate what\n",
    "- Clear priorities for what to fix first  \n",
    "- Numbers to track if improvements work\n",
    "- Data to back up product decisions\n",
    "\n",
    "### What's next:\n",
    "1. Hook this up to real survey data\n",
    "2. Maybe train custom models on education-specific text\n",
    "3. Automate reports so we don't have to run this manually\n",
    "4. A/B testing framework to see if fixes work\n",
    "5. Real-time monitoring for new feedback\n",
    "\n",
    "Pretty solid foundation for understanding user feedback and fixing the right things.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
